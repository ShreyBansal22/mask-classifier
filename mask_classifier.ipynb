{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Dropout, Flatten, Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Found 750 images belonging to 2 classes.\nFound 350 images belonging to 2 classes.\n"
    }
   ],
   "source": [
    "train_path='Mask_Datasets\\Train'\n",
    "test_path='Mask_Datasets\\Validation'\n",
    "\n",
    "\n",
    "train_batches=ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        train_path,\n",
    "        color_mode='grayscale',\n",
    "        target_size=(150, 150),\n",
    "        shuffle=True,\n",
    "        classes=['Mask','No_mask'])\n",
    "            \n",
    "test_batches=ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        test_path,\n",
    "        target_size=(150, 150),\n",
    "        shuffle=True,\n",
    "        color_mode='grayscale',\n",
    "        classes=['Mask','No_mask'])\n",
    "epochs=30\n",
    "width,height=150,150\n",
    "num_features=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Found 750 images belonging to 2 classes.\nFound 350 images belonging to 2 classes.\nModel: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_1 (Conv2D)            (None, 148, 148, 64)      640       \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 74, 74, 64)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 72, 72, 64)        36928     \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 36, 36, 64)        0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 34, 34, 128)       73856     \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 17, 17, 128)       0         \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 15, 15, 128)       147584    \n_________________________________________________________________\nmax_pooling2d_4 (MaxPooling2 (None, 7, 7, 128)         0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 6272)              0         \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 6272)              0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 120)               752760    \n_________________________________________________________________\ndense_2 (Dense)              (None, 2)                 242       \n=================================================================\nTotal params: 1,012,010\nTrainable params: 1,012,010\nNon-trainable params: 0\n_________________________________________________________________\nEpoch 1/25\n24/24 [==============================] - 41s 2s/step - loss: 0.7148 - accuracy: 0.5453 - val_loss: 0.6786 - val_accuracy: 0.7686\nEpoch 2/25\n24/24 [==============================] - 42s 2s/step - loss: 0.6051 - accuracy: 0.7133 - val_loss: 0.6714 - val_accuracy: 0.7914\nEpoch 3/25\n24/24 [==============================] - 44s 2s/step - loss: 0.5147 - accuracy: 0.7707 - val_loss: 0.4507 - val_accuracy: 0.8343\nEpoch 4/25\n24/24 [==============================] - 46s 2s/step - loss: 0.4442 - accuracy: 0.8133 - val_loss: 0.2243 - val_accuracy: 0.8686\nEpoch 5/25\n24/24 [==============================] - 44s 2s/step - loss: 0.3615 - accuracy: 0.8507 - val_loss: 0.2557 - val_accuracy: 0.8600\nEpoch 6/25\n24/24 [==============================] - 46s 2s/step - loss: 0.2882 - accuracy: 0.8787 - val_loss: 0.2495 - val_accuracy: 0.9257\nEpoch 7/25\n24/24 [==============================] - 45s 2s/step - loss: 0.2484 - accuracy: 0.9000 - val_loss: 0.1327 - val_accuracy: 0.9143\nEpoch 8/25\n24/24 [==============================] - 47s 2s/step - loss: 0.1959 - accuracy: 0.9160 - val_loss: 0.0943 - val_accuracy: 0.9514\nEpoch 9/25\n24/24 [==============================] - 48s 2s/step - loss: 0.1775 - accuracy: 0.9453 - val_loss: 0.3651 - val_accuracy: 0.9314\nEpoch 10/25\n24/24 [==============================] - 48s 2s/step - loss: 0.1399 - accuracy: 0.9467 - val_loss: 0.0349 - val_accuracy: 0.9686\nEpoch 11/25\n24/24 [==============================] - 47s 2s/step - loss: 0.1239 - accuracy: 0.9560 - val_loss: 0.0547 - val_accuracy: 0.9657\nEpoch 12/25\n24/24 [==============================] - 47s 2s/step - loss: 0.1097 - accuracy: 0.9627 - val_loss: 0.1050 - val_accuracy: 0.9600\nEpoch 13/25\n24/24 [==============================] - 48s 2s/step - loss: 0.1087 - accuracy: 0.9613 - val_loss: 0.0797 - val_accuracy: 0.9743\nEpoch 14/25\n24/24 [==============================] - 49s 2s/step - loss: 0.1043 - accuracy: 0.9640 - val_loss: 0.1376 - val_accuracy: 0.9771\nEpoch 15/25\n24/24 [==============================] - 48s 2s/step - loss: 0.0847 - accuracy: 0.9640 - val_loss: 0.1368 - val_accuracy: 0.9486\nEpoch 16/25\n24/24 [==============================] - 50s 2s/step - loss: 0.0744 - accuracy: 0.9787 - val_loss: 0.0734 - val_accuracy: 0.9771\nEpoch 17/25\n24/24 [==============================] - 49s 2s/step - loss: 0.0596 - accuracy: 0.9800 - val_loss: 0.0298 - val_accuracy: 0.9743\nEpoch 18/25\n24/24 [==============================] - 48s 2s/step - loss: 0.0309 - accuracy: 0.9867 - val_loss: 0.0056 - val_accuracy: 0.9829\nEpoch 19/25\n24/24 [==============================] - 49s 2s/step - loss: 0.0310 - accuracy: 0.9907 - val_loss: 0.1947 - val_accuracy: 0.9714\nEpoch 20/25\n24/24 [==============================] - 49s 2s/step - loss: 0.0305 - accuracy: 0.9920 - val_loss: 0.0529 - val_accuracy: 0.9800\nEpoch 21/25\n24/24 [==============================] - 49s 2s/step - loss: 0.0481 - accuracy: 0.9867 - val_loss: 0.3463 - val_accuracy: 0.9429\nEpoch 22/25\n24/24 [==============================] - 49s 2s/step - loss: 0.0449 - accuracy: 0.9800 - val_loss: 0.0063 - val_accuracy: 0.9600\nEpoch 23/25\n24/24 [==============================] - 50s 2s/step - loss: 0.0357 - accuracy: 0.9880 - val_loss: 0.0257 - val_accuracy: 0.9771\nEpoch 24/25\n24/24 [==============================] - 50s 2s/step - loss: 0.0234 - accuracy: 0.9933 - val_loss: 0.3458 - val_accuracy: 0.9629\nEpoch 25/25\n24/24 [==============================] - 49s 2s/step - loss: 0.0306 - accuracy: 0.9893 - val_loss: 0.0769 - val_accuracy: 0.9771\n"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "model=Sequential()\n",
    "\n",
    "model.add(Conv2D(num_features,(3,3),activation='relu',input_shape=(width,height,1)))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "model.add(Conv2D(num_features,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "model.add(Conv2D(2*num_features,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "model.add(Conv2D(2*num_features,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(120,activation='relu'))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy']\n",
    "             )\n",
    "             \n",
    "history=model.fit_generator(train_batches,epochs=25,\n",
    "                           validation_data=test_batches,verbose=1,shuffle=True)       \n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "model.save('mask.h5') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "\n",
    "#load model\n",
    "model = load_model('mask.h5')\n",
    "\n",
    "face_haar_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "\n",
    "cap=cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret,test_img=cap.read()\n",
    "    if not ret:\n",
    "        continue\n",
    "    gray_img= cv2.cvtColor(test_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces_detected = face_haar_cascade.detectMultiScale(gray_img,1.32,5)\n",
    "\n",
    "\n",
    "    for (x,y,w,h) in faces_detected:\n",
    "        cv2.rectangle(test_img,(x,y),(x+w,y+h),(255,0,0),thickness=7)\n",
    "        roi_gray=gray_img[y:y+w,x:x+h]\n",
    "        roi_gray=cv2.resize(roi_gray,(150,150))\n",
    "        img_pixels = image.img_to_array(roi_gray)\n",
    "        img_pixels = np.expand_dims(img_pixels, axis = 0)\n",
    "        img_pixels /= 255\n",
    "        predictions = model.predict(img_pixels)\n",
    "\n",
    "        #find max indexed array\n",
    "        max_index = np.argmax(predictions[0])\n",
    "\n",
    "        emotions = ('Mask','No Mask')\n",
    "        predicted_emotion = emotions[max_index]\n",
    "\n",
    "        cv2.putText(test_img, predicted_emotion, (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "\n",
    "    resized_img = cv2.resize(test_img, (1000, 700))\n",
    "    cv2.imshow('Mask or no mask detection',resized_img)\n",
    "    if cv2.waitKey(1) & 0xFF==ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}